services:
  prompt_server:
    image: harbor.vastaitech.com/ai_deliver/vllm_vacc:v0.9.0.1Rer
    container_name: prompt_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - 11222:8000
    cap_add:
      - SYS_ADMIN
    environment:
      - VACC_LOG_LEVEL=critical,critical
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
      - PROMPT_SERVER_MODEL=Qwen3-0.6B
      - PROMPT_SERVER_PGU_USAGE=0.3
      - MODEL_DIR
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    command: 
      - -c
      - |
        exec taskset -c 64-95 python3 -m vllm.entrypoints.openai.api_server --model /weights/$PROMPT_SERVER_MODEL --max-model-len 16384 --gpu-memory-utilization ${PROMPT_SERVER_PGU_USAGE}  --port 8000 --served-model-name prompt_model
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              device_ids: ["0"]

  guard_server:
    image: harbor.vastaitech.com/ai_deliver/vllm_vacc:v0.9.0.1Rer
    container_name: guard_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - 11223:8898
    cap_add:
      - SYS_ADMIN
    environment:
      - VACC_LOG_LEVEL=critical,critical
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
      - GUARD_SERVER_MODEL=ChineseGuard-1.5B
      - GUARD_SERVER_GPU_USAGE=0.2
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    command: 
      - -c
      - |
        exec taskset -c 64-95 python3 -m vllm.entrypoints.openai.api_server --model /weights/${GUARD_SERVER_MODEL} --max-model-len 1024  --gpu-memory-utilization ${GUARD_SERVER_GPU_USAGE}  --port 8898 --served-model-name safe-guard 

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              device_ids: ["0"]

  embedding_server:
    image: harbor.vastaitech.com/ai_deliver/vllm_vacc:v0.9.0.1Rer
    container_name: embedding_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - 11224:9998
    cap_add:
      - SYS_ADMIN
    environment:
      - VACC_LOG_LEVEL=critical,critical
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
      - EMBEDDING_SERVER_MODEL=Qwen3-Embedding-0.6B
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    command: 
      - -c
      - |
        exec taskset -c 64-95 python3 -m vllm.entrypoints.openai.api_server --model /weights/${EMBEDDING_SERVER_MODEL} --port 9998 --served-model-name qwen3-embedding 

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              device_ids: ["0"]

  rerank_server:
    image: harbor.vastaitech.com/ai_deliver/vllm_vacc:v0.9.0.1Rer
    container_name: rerank_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - 11225:9999
    cap_add:
      - SYS_ADMIN
    environment:
      - VACC_LOG_LEVEL=critical,critical
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
      - RERANK_SERVER_MODEL=Qwen3-Reranker-0.6B
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    command: 
      - -c
      - |
        exec taskset -c 64-95 vllm serve  /weights/${RERANK_SERVER_MODEL} --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}' --gpu-memory-utilization 0.09 --port 9999 --served-model-name qwen3-reranker

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              device_ids: ["0"]
